{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/digit-recognizer/train.csv\n",
      "/kaggle/input/digit-recognizer/test.csv\n",
      "/kaggle/input/digit-recognizer/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Additional imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_shape: (42000, 785)\n",
      "test_data_shape: (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "train_data_raw = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\n",
    "test_data_raw = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\n",
    "\n",
    "print('train_data_shape: ' + str(train_data_raw.shape))\n",
    "print('test_data_shape: ' + str(test_data_raw.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### Pre processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pre_process_data(dataset, has_label=True):\n",
    "    if has_label:\n",
    "        data = dataset.iloc[:,1:].values\n",
    "    else:\n",
    "        data = dataset.iloc[:,:].values\n",
    "        \n",
    "    data = data.astype(np.float)\n",
    "    \n",
    "    data = np.multiply(data, 1.0 / 255.0)\n",
    "        \n",
    "    return data\n",
    "\n",
    "train_images = pre_process_data(train_data_raw)\n",
    "\n",
    "train_images"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### Pre processing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "def pre_process_labels(data):\n",
    "    labels_flat = data.iloc[:,0].values.ravel()\n",
    "    num_classes = np.unique(labels_flat).shape[0]\n",
    "    \n",
    "    num_labels = labels_flat.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_flat.ravel()] = 1\n",
    "\n",
    "    return labels_one_hot.astype(np.uint8)\n",
    "\n",
    "train_labels = pre_process_labels(train_data_raw)\n",
    "\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Showing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_size = train_images.shape[1]\n",
    "image_width = image_height = np.ceil(np.sqrt(image_size)).astype(np.uint8)\n",
    "\n",
    "def display(img):\n",
    "    \n",
    "    # (784) => (28,28)\n",
    "    one_image = img.reshape(image_width, image_height)\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.imshow(one_image, cmap=cm.binary)\n",
    "\n",
    "display(train_images[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (42000, 784)\n",
      "Labels shape: (42000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Images shape: \" + str(train_images.shape))\n",
    "print(\"Labels shape: \" + str(train_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(train_images, train_labels, config):\n",
    "    NUM_EPOCHS = config['NUM_EPOCHS']\n",
    "    BATCH_SIZE = config['BATCH_SIZE']\n",
    "    LEARNING_RATE = config['LEARNING_RATE']\n",
    "    DROPOUT_RATE = config['DROPOUT_RATE']\n",
    "    NETWORK_WIDTH = config['NETWORK_WIDTH']\n",
    "\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Input(shape=(784,)),\n",
    "        keras.layers.Dense(NETWORK_WIDTH, activation='swish'),\n",
    "        keras.layers.Dropout(DROPOUT_RATE),\n",
    "        keras.layers.Dense(NETWORK_WIDTH, activation='swish'),\n",
    "        keras.layers.Dropout(DROPOUT_RATE),\n",
    "        keras.layers.Dense(NETWORK_WIDTH, activation='swish'),\n",
    "        keras.layers.Dropout(DROPOUT_RATE),\n",
    "        keras.layers.Dense(NETWORK_WIDTH, activation='swish'),\n",
    "        keras.layers.Dropout(DROPOUT_RATE),\n",
    "        keras.layers.Dense(NETWORK_WIDTH, activation='swish'),\n",
    "        keras.layers.Dropout(DROPOUT_RATE),\n",
    "        keras.layers.Dense(NETWORK_WIDTH, activation='swish'),\n",
    "        keras.layers.Dropout(DROPOUT_RATE),\n",
    "        keras.layers.Dense(NETWORK_WIDTH, activation='swish'),\n",
    "        keras.layers.Dense(NETWORK_WIDTH, activation='tanh'),\n",
    "        keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "    loss = 'mean_squared_error'\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    \n",
    "    val_size = int(train_images.shape[0] * 0.2)\n",
    "\n",
    "    val_images = train_images[:val_size,:]\n",
    "    val_labels = train_labels[:val_size,:]\n",
    "\n",
    "    train_images = train_images[val_size:,:]\n",
    "    train_labels = train_labels[val_size:,:]\n",
    "\n",
    "    hist = model.fit(\n",
    "        x=train_images, y=train_labels,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_steps=10,\n",
    "        validation_data=(val_images, val_labels),\n",
    "        verbose=1,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    loss, acc = model.evaluate(val_images, val_labels)\n",
    "    \n",
    "    return model, loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "263/263 [==============================] - 8s 31ms/step - loss: 0.0393 - accuracy: 0.8303 - val_loss: 0.0162 - val_accuracy: 0.9352\n",
      "Epoch 2/20\n",
      "263/263 [==============================] - 8s 30ms/step - loss: 0.0151 - accuracy: 0.9308 - val_loss: 0.0094 - val_accuracy: 0.9547\n",
      "Epoch 3/20\n",
      "263/263 [==============================] - 8s 30ms/step - loss: 0.0106 - accuracy: 0.9465 - val_loss: 0.0071 - val_accuracy: 0.9656\n",
      "Epoch 4/20\n",
      "263/263 [==============================] - 8s 29ms/step - loss: 0.0088 - accuracy: 0.9536 - val_loss: 0.0061 - val_accuracy: 0.9656\n",
      "Epoch 5/20\n",
      "263/263 [==============================] - 8s 30ms/step - loss: 0.0075 - accuracy: 0.9596 - val_loss: 0.0073 - val_accuracy: 0.9609\n",
      "Epoch 6/20\n",
      "263/263 [==============================] - 8s 29ms/step - loss: 0.0070 - accuracy: 0.9619 - val_loss: 0.0048 - val_accuracy: 0.9750\n",
      "Epoch 7/20\n",
      "263/263 [==============================] - 8s 31ms/step - loss: 0.0065 - accuracy: 0.9649 - val_loss: 0.0048 - val_accuracy: 0.9727\n",
      "Epoch 8/20\n",
      "263/263 [==============================] - 8s 30ms/step - loss: 0.0061 - accuracy: 0.9662 - val_loss: 0.0043 - val_accuracy: 0.9773\n",
      "Epoch 9/20\n",
      "263/263 [==============================] - 8s 30ms/step - loss: 0.0055 - accuracy: 0.9690 - val_loss: 0.0047 - val_accuracy: 0.9766\n",
      "Epoch 10/20\n",
      "263/263 [==============================] - 8s 30ms/step - loss: 0.0053 - accuracy: 0.9712 - val_loss: 0.0052 - val_accuracy: 0.9711\n",
      "Epoch 11/20\n",
      "263/263 [==============================] - 8s 30ms/step - loss: 0.0049 - accuracy: 0.9730 - val_loss: 0.0039 - val_accuracy: 0.9789\n",
      "Epoch 12/20\n",
      "263/263 [==============================] - 8s 29ms/step - loss: 0.0049 - accuracy: 0.9726 - val_loss: 0.0037 - val_accuracy: 0.9797\n",
      "Epoch 13/20\n",
      "263/263 [==============================] - 8s 30ms/step - loss: 0.0047 - accuracy: 0.9736 - val_loss: 0.0040 - val_accuracy: 0.9773\n",
      "Epoch 14/20\n",
      "263/263 [==============================] - 8s 30ms/step - loss: 0.0045 - accuracy: 0.9755 - val_loss: 0.0044 - val_accuracy: 0.9758\n",
      "Epoch 15/20\n",
      "263/263 [==============================] - 8s 31ms/step - loss: 0.0044 - accuracy: 0.9754 - val_loss: 0.0037 - val_accuracy: 0.9781\n",
      "Epoch 16/20\n",
      "263/263 [==============================] - 8s 30ms/step - loss: 0.0040 - accuracy: 0.9783 - val_loss: 0.0042 - val_accuracy: 0.9781\n",
      "Epoch 17/20\n",
      "263/263 [==============================] - 8s 30ms/step - loss: 0.0039 - accuracy: 0.9791 - val_loss: 0.0040 - val_accuracy: 0.9773\n",
      "Epoch 18/20\n",
      "263/263 [==============================] - 8s 30ms/step - loss: 0.0040 - accuracy: 0.9778 - val_loss: 0.0043 - val_accuracy: 0.9773\n",
      "Epoch 19/20\n",
      "263/263 [==============================] - 8s 30ms/step - loss: 0.0036 - accuracy: 0.9801 - val_loss: 0.0040 - val_accuracy: 0.9781\n",
      "Epoch 20/20\n",
      "263/263 [==============================] - 8s 30ms/step - loss: 0.0037 - accuracy: 0.9793 - val_loss: 0.0047 - val_accuracy: 0.9734\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 0.0055 - accuracy: 0.9687\n",
      "Accuracy: 96.86904549598694%\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'BATCH_SIZE': 128,\n",
    "    'LEARNING_RATE': 0.001,\n",
    "    'DROPOUT_RATE': 0.4,\n",
    "    'NUM_EPOCHS': 20,\n",
    "    'NETWORK_WIDTH': 512\n",
    "}\n",
    "\n",
    "model, loss, acc = fit(train_images, train_labels, config)\n",
    "\n",
    "print('Accuracy: ' + str(acc * 100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pre_process_data(test_data_raw, False)\n",
    "\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.65304607e-03, -3.95392999e-04,  1.02586198e+00, ...,\n",
       "         2.80941278e-02,  7.69187137e-03, -3.00471392e-03],\n",
       "       [ 1.11048853e+00, -1.95757616e-02, -5.19108027e-03, ...,\n",
       "        -3.02324295e-02, -3.72465625e-02, -4.92885988e-03],\n",
       "       [ 9.51483846e-04,  2.34186836e-03,  1.31195839e-02, ...,\n",
       "        -1.53425038e-02,  1.84490308e-02,  9.86111045e-01],\n",
       "       ...,\n",
       "       [-1.74462907e-02,  5.49597479e-03, -2.54517421e-03, ...,\n",
       "         3.62050161e-03, -1.73446611e-02, -1.97224319e-02],\n",
       "       [ 4.80190665e-03,  1.27113797e-03,  1.25542525e-02, ...,\n",
       "        -1.66599788e-02,  6.15351647e-03,  1.00485468e+00],\n",
       "       [ 3.98688018e-03, -9.72164795e-04,  1.01826823e+00, ...,\n",
       "         2.58094519e-02,  7.64657557e-03, -4.29491606e-03]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submissions for Kaggle\n",
    "submissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n",
    "                         \"Label\": np.argmax(predictions, axis=1)})\n",
    "submissions.to_csv(\"my_submissions.csv\", index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
